{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2118a69",
   "metadata": {},
   "source": [
    "Primeiro vamos importar o dataset para a variável dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dts = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c9e9d",
   "metadata": {},
   "source": [
    "Precisamos dar uma olhada nesse dataset para entendermos quais os tipos de dados que ele possui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97341d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79cabd4",
   "metadata": {},
   "source": [
    "Em resumo, todos os dados são números com excessão do coluna diagnosis, vamos entender do que se trata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dts[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fea9f9",
   "metadata": {},
   "source": [
    "O dataset em questão trata os tipos de tumores, dessa forma temos o valor \"B\" para Benigno e \"M\" para Maligno, precisaremos alterá-los para números para podermos tratá-los corretamente no futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034cec6",
   "metadata": {},
   "source": [
    "Também é interessante entendermos como esses valores estão distribuídos no dataset para enterdemos se há algum tipo de assimetria muito grande nos dados, vamos ver uma descrição desse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c0607",
   "metadata": {},
   "source": [
    "Com isso já temos muitas informações dos valores, incluindo uma muito importante, count, que por conta de ela ter o valor igual em todos as features, podemos ver que esse dataset possui todas as tabelas preenchidas, e não há nenhum valor faltante nas colunas, mas infelizmente é um banco bem pequeno, o que pode enviezar o nosso modelo em quantidades mais elevadas de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee65df4",
   "metadata": {},
   "source": [
    "Também vamos realizar uma visualização mais gráfica para entender se há algum dado muito unilateral no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dts.hist(bins=50, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db1e31",
   "metadata": {},
   "source": [
    "Podermos ver que a maioria desses dados desse dataset já foram tratados anteriormente, o que facilitará nosso processo de análise e treino, porém, por ser um dataset muito pequeno, não será possível darmos um tratamento mais eficiente em algumas features, pois corremos um risco muito alto de overfiting caso realizemos esse tratamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd3274",
   "metadata": {},
   "source": [
    "Agora sim vamos começar. Primeiro vamos separar a coluna \"diagnosis\" das outras pois ela é a nossa target já que possuí o resultado, também vamos adicionar as outras colunas como sendo nossa feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'diagnosis'\n",
    "X = dts.drop(columns=[target_column])\n",
    "y = dts[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f44f64",
   "metadata": {},
   "source": [
    "Também vamos aproveitar para remapear a coluna diagnosis para valores numéricos, nesse caso, vamos configurá-la para \"0\" como sendo Benigno e \"1\" como sendo \"Maligno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.map({'B': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571597e",
   "metadata": {},
   "source": [
    "Para podermos configurar a pipeline, vamos adicionar todos os valores númericos restantes, para a nossa nova variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dabe2",
   "metadata": {},
   "source": [
    "Antes de treinarmos nossos modelos, vamos verificar se existe alguma correlação nos dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff661533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_target = pd.concat([X, y], axis=1)\n",
    "corr_matrix  = df_corr_target.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbd63e",
   "metadata": {},
   "source": [
    "Vamos verificar se algum dos dados estão correlacionados com a nossa feature mais importante, a 'diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae037d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_diagnosis = corr_matrix[target_column].sort_values(ascending=False)\n",
    "print(corr_diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd65047",
   "metadata": {},
   "source": [
    "Podemos ver que existe uma correlação similar na maioria dos dados, não uma que se destaca das outras, isso pode ser por conta do nosso dataset ser muito pequeno, o que pode causar esse tipo de correlação entre os dados, outra motivação pode ser por se tratar de algo biológico como o câncer, onde não temos um motivo específico para que ele aconteça, e sim uma junção de fatores que podem ou não causar a doença"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f931d0",
   "metadata": {},
   "source": [
    "E os outros dados, será que existem uma correlação entre eles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e208ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='Reds', fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Gráfico de correlação\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343ff80",
   "metadata": {},
   "source": [
    "Nesse gráfico podemos notar que existem muitos valores semelhantes em quantidade entre os valores, justamente da forma que havíamos discutido anteriormente, mas existem algumas correlações que sabemos exatamente como se comportam na vida real, como por exemplo, a correlação entre o raio, o perímetro e a área de um círculo perfeito, onde uma sempre aumentará a outra, que é o que gráfico também \n",
    "está indicando para nós"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede942a0",
   "metadata": {},
   "source": [
    "Vamos realizar um gráfico mais específico entre os valores \"radius_mean\", \"perimeter_mean\" e \"area_mean\" para entendermos como essas correlações estão ocorrendo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"radius_mean\", \"perimeter_mean\", \"area_mean\"]\n",
    "scatter_matrix(corr_matrix[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922f879",
   "metadata": {},
   "source": [
    "Como dito anteriormente, penansdo em matemática, esses valores andam juntos em uma forma circular perfeita, e por conta disso. podemos ver que a medida que um deles aumenta, os outros também aumentam em conjunto, provando que esses valores foram descritos corretamente em nosso dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665ffe1",
   "metadata": {},
   "source": [
    "Em nosso caso específico, temos o interesse em saber, quando o nosso modelo irá marcar um diagnóstico para 0 (Benigno) ou 1 (Maligno), e para isso, podemos montar um gráfico para entendermos a correlação dos valores gerais com o nosso valor target que é \"diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_without_target = corr_matrix[target_column].sort_values(ascending=False).drop(target_column)\n",
    "sns.barplot(x=corr_without_target.values, y=corr_without_target.index)\n",
    "plt.title(f'Correlação das Features com o Diagnóstico ({target_column})')\n",
    "plt.xlabel('Nível de Correlação')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210e882",
   "metadata": {},
   "source": [
    "Nesse gráfico, conseguimos entender que quanto maior os valores das variáveis, maior a chance do tumor ser maligno para o nosso diagnóstico, e também conseguimos notar que algumas variáveis como \"smoothness_se\", possuí uma importância invertida ao tumor maligno, ou seja, quanto maior esse valor, menos chance do tumor ser maligno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b06b9a",
   "metadata": {},
   "source": [
    "Bom, conseguimos tirar vários dados interessantes nesses testes que fizemos, mas agora chegamos a parte que interessa, vamos realizar a criação do nosso modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2f120",
   "metadata": {},
   "source": [
    "Configurando a pipeline de pré processamento dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_features)], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5330166",
   "metadata": {},
   "source": [
    "Separando os dados treino e e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57fec7",
   "metadata": {},
   "source": [
    "Para enterdemos se a separação foi boa, podemos utilizar o comando abaixo para termos uma visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), \"treinamento +\", len(X_test), \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebfeb08",
   "metadata": {},
   "source": [
    "Tivemos uma separação decente para o nosso modelo, porém, visto que os dados possuem um volume muito baixo, podemos ter alguns resultados inesperados futuramente, mas por agora, vamos dar continuidade à criação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed46f4",
   "metadata": {},
   "source": [
    "Vamos dar início ao treinamento dos nossos modelos, para quesitos de teste, utilizarei 3 modelos diferentes, para entendermos como eles se comportam. Utilizarei a Regressão logística, a Árvore de decisões e o KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05102af3",
   "metadata": {},
   "source": [
    "REGRESSÃO LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model_reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(random_state=42, solver='liblinear'))])\n",
    "\n",
    "model_reg_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b70b59",
   "metadata": {},
   "source": [
    "Vamos availiar o modelo para utilizando a métrica Recall pois essa métrica pende bastante a evitar falsos negativos, onde o modelo diria que o paciente não possuí uma doença, mesmo ele tendo. Obviamente esse é o pior caso para a medicina, pois muitos pacientes não seriam tratados caso o modelo não tenha uma boa nota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_pred_reg = model_reg_pipeline.predict(X_test)\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_reg, zero_division=0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba875e",
   "metadata": {},
   "source": [
    "Uma nota como essa é excelente para qualquer modelo, ainda mais para um modelo de diagnósticos médicos que criamos, porém, isso pode ser justamente por conta da quantidade baixa de dados que possuímos em nosso dataset, precisaríamos de uma quantidade muito maior para conseguirmos entender exatamente como ele foi, mas para um teste, essa nota é perfeita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be64aea",
   "metadata": {},
   "source": [
    "Vamos criar um gráfico para entender melhor o quanto ele foi bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm_reg = confusion_matrix(y_test, y_pred_reg)\n",
    "sns.heatmap(cm_reg, annot=True, fmt='d',\n",
    "            xticklabels=['Benigno (0)', 'Maligno (1)'],\n",
    "            yticklabels=['Benigno (0)', 'Maligno (1)'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão - Regressão logística')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c284e9f4",
   "metadata": {},
   "source": [
    "Vamos entender esse gráfico, no canto superior esquerdo, temos a quantidade de acertos negativos do nosso modelo, 71, indicando quantas vezes ele identificou corretamente que o paciente não possuía uma doença.\n",
    "No canto superior direito, temos justamente o contrário, quantas vezes ele pensou que o paciente possuía uma doença, mesmo ele não tendo, tivemos apenas 1 caso.\n",
    "No canto inferior esquerdo, temos o mais perigoso, quantas vezes ele indicou que o paciente não possuía uma doença, mesmo ele tendo, tivemos 2 casos.\n",
    "Por fim, temos o canto inferior direito, que indica os acertos positivos do nosso modelo, ou seja, quantas vezes ele informou corretamente que um paciente possuía a doença, tivemos 40 casos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30656c91",
   "metadata": {},
   "source": [
    "Apesas de ter ocorrido 2 casos onde ele indicou erroneamente que o paciente não possuía a doença, temos um modelo bastante decente para utilização, que estaria acertando a maioria dos casos, lembrando novamente que esse valor alto de acertos pode ser justamente por nossa base ser muito pequena para os testes, e o recomendado seria termos um novo teste, com uma base bem maior para termos um resultado justificativo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12734a61",
   "metadata": {},
   "source": [
    "Tudo parece muito bom, mas vamos ver como os outros modelos se saem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb0dc4",
   "metadata": {},
   "source": [
    "ÁRVORE DE DECISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "model_tree_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "model_tree_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad51671",
   "metadata": {},
   "source": [
    "Vamos availiar o modelo para utilizando o Roc Auc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e49199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "y_pred_tree = model_tree_pipeline.predict(X_test)\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_tree):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248b73f",
   "metadata": {},
   "source": [
    "Vamos criar um gráfico para entender melhor o quanto ele foi bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "sns.heatmap(cm_tree, annot=True, fmt='d',\n",
    "            xticklabels=['Benigno (0)', 'Maligno (1)'],\n",
    "            yticklabels=['Benigno (0)', 'Maligno (1)'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão - Árvore de decisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c29c8",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ed09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "model_knn_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('classifier', KNeighborsClassifier(n_neighbors=5))])\n",
    "model_knn_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d900cc8",
   "metadata": {},
   "source": [
    "Vamos availiar o modelo para utilizando o Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "y_pred_knn = model_knn_pipeline.predict(X_test)\n",
    "\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_knn):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043f074",
   "metadata": {},
   "source": [
    "Vamos criar um gráfico para entender melhor o quanto ele foi bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d',\n",
    "            xticklabels=['Benigno (0)', 'Maligno (1)'],\n",
    "            yticklabels=['Benigno (0)', 'Maligno (1)'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão - K-Nearest Neighbors (KNN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189a989",
   "metadata": {},
   "source": [
    "Ambos os modelos de Árvore de decisão e KNN, tiraram a mesma nota no Recall score de 90,4%, e tiveram 4 falhas críticas onde indicaram de forma incorreta, que o paciente não possuía a doença, porém, uma diferença a se notar é que no modelo de Árvore de decisão, também tivemos um número maior de falsos positivos, indicando que esse modelo não seria uma boa escolha para a nossa tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8341c",
   "metadata": {},
   "source": [
    "No final ficamos com a Regressão logística em primeiro lugar, o KNN em segundo, e a Árvore de decisão em terceiro, e com base nisso poderíamos dizer que a Regressão logística, é o melhor modelo para esse exemplo, mas apesar disso, todos os modelos performaram muito bem, porém, para termos um modelo que possa ser utilizado profissionalmente um teste maior, com mais dados, e mais informações deve ser realizado em ordem de termos um resultado mais parecido com a realidade, onde temos diversos fatores que podem alterar o resultado final desse teste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
